# RA-120450017

# Three Ways of Storing and Accessing Lots of Images in Python

## Setup
* kumpulan data
Dataset yang digunakan adalah CIFAR-10, yang dapat diekstra dengan syntax cPickle.

```
import numpy as np
import pickle
from pathlib import Path

# Path to the unzipped CIFAR data
data_dir = Path("data/cifar-10-batches-py/")

# Unpickle function provided by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}") 
```

* menyimpan disk gambar
Menyiapkan software untuk menyimpan gambar:
- menggunakan Pillow untuk manipulasi gambar
```
$ pip install Pillow
```
- menggunakan anaconda
```
conda install -c conda-forge pillow
```

PIL (Pyhton Imaging Library) jadi jika sudah ada dapat dihapus, diganti menggunakan Pillow.

* menggunakan LMDB

Lightnung memory-mapped databse (LMDB) adalah database cepat yang menggunakan file yang dipetakan dengan memori. Ini menggunakan pohon B+ untuk efisiensi dan dapat diakses melalui pengikatan Python.
```
$ pip install lmdb
```
- menggunakan anaconda
```
$ conda install -c conda-forge python-lmdb
```
dapat diperiksa apakah lmdb dari shell dapat digunakan.

* menggunakan HDF5

HDF5 adalah format file Hierarchical Data Format yang digunakan untuk menyimpan data ilmiah. Format ini terdiri dari kumpulan data dan grup, dengan dataset sebagai array multidimensi.
```
$ pip install h5py
```
- menggunakan anaconda
```
$ conda install -c conda-forge h5py
```
jika dapat mengimport h5py dari python, maka sudah dapat digunakan.

## Storing a single image

Beberapa metode dapat dioptimalkan untuk jumlah file yang berbeda. Untuk eksperimen, perbandingan dilakukan antara berbagai jumlah file, mulai dari satu gambar hingga 100.000 gambar. Ada lima kelompok CIFAR-10 yang berjumlah 50.000 gambar, sehingga setiap gambar dapat digunakan dua kali untuk mencapai 100.000 gambar. Percobaan ini memerlukan pembuatan folder untuk setiap metode, dengan semua file database atau citra disimpan di dalamnya. Path ke direktori ini disimpan dalam variabel untuk persiapan percobaan.

```
from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
```
Path tidak secara otomatis membuat suatu folder.

```
disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True)
```
Dapat menjalankan eskperimen yang sebenarnya dengan kode yang berbeda.


* dengan disk

Sebuah gambar gambar tunggal, yang saat ini berada di memori sebagai larik NumPy dapat disimpan terlebih dahulu ke dalam disk sebagai gambar .png, dan menamainya dengan menggunakan ID gambar yang unik image_id. Hal ini dapat dilakukan dengan menggunakan paket Pillow yang telah diinstal sebelumnya:

```
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```  
Hal ini akan menyimpan gambar pada semua aplikasi realistis, contoh dataset adalah label gambar. Ketika menyimpan gambar ke disk. Ada beberapa opsi untuk menyimpan meta data, salah satu solusinya adalah dengan mengkodekan label ke dalam nama gambar. Hal ini memiliki keuntungan karena tidak memerlukan file tambahan.

Adapun kelemahann dalam meta data, yaitu memaksa menyimpan gambar dalam semua label. Dengan menyimpan label dalam file terpisah, maka yang dapat digunakan hanya labelnya saja, tanpa harus memuat gambarnya. 

* dengan LMDB

Pertama, LMDB adalah sistem penyimpanan nilai-kunci di mana setiap entri disimpan sebagai larik byte. Baik kunci dan nilai diharapkan berupa string, jadi penggunaan yang umum adalah untuk menserialisasi nilai sebagai string, dan kemudian unserialisasi ketika membacanya kembali.

```
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary 
        # for this dataset, but some datasets may include images of 
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```
Kedua, karena LMDB dipetakan dengan memori, database baru perlu mengetahui berapa banyak memori yang akan digunakan. LMDB menyebut variabel ini sebagai map_size.

Terakhir, operasi baca dan tulis dengan LMDB dilakukan dalam transaksi.

Dengan mengingat ketiga poin tersebut, maka kode untuk menyimpan satu gambar ke LMDB sebagai berikut:

```
import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```

* dengan HDF5

File HDF5 dapat berisi lebih dari satu kumpulan data. Dari kode di bawah daapat dilakukan dengan cara membuat dua set data, satu untuk gambar, dan satu lagi untuk meta datanya:

```
import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```
Pilihan tipe data akan sangat memengaruhi runtime dan persyaratan penyimpanan HDF5.

* eksperimen menyimpan gambar tunggal

Menempatkan ketiga fungsi untuk menyimpan satu gambar ke dalam kamus, yang bisa dipanggil nanti sewaktu melakukan eksperimen waktu:

```
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```
Setelah siap untuk melakukan eksperimen waktu. Maka dapat dilakukan menyimpan gambar pertama dari CIFAR dan label yang sesuai, dan menyimpannya dengan tiga cara yang berbeda:

```
from timeit import timeit

store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

Ingatlah bahwa pada runtime, yang ditampilkan di sini dalam hitungan detik, dan juga penggunaan memori:

| Method | Save Single Image + Meta| Memory |
| ------ | ------------------------| -------| 
| Disk   | 1.915 ms                |8 K     | 
| LMDB   | 1.203 ms                |32 K    | 
| HDF5   | 8.243 ms                |8 K     | 

Ada dua hal yang bisa diambil di sini:

- Semua metode ini sangat cepat.
- Dari segi penggunaan disk, LMDB menggunakan lebih banyak.

## Storing many images

* penyesesuaian code untuk banyak gambar

Menyimpan banyak gambar sebagai file .png sangat mudah dengan store_single_method(). Namun hal ini tidak berlaku untuk LMDB atau HDF5, karena tidak menginginkan file database yang berbeda untuk setiap gambar. Perlu dilakukan pengubahan kode dan membuat tiga fungsi baru yang menerima banyak gambar, store_many_disk(), store_many_lmdb(), dan store_many_hdf5:

```
store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before — but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```
Agar dapat menyimpan lebih dari satu berkas ke disk, metode berkas gambar diubah untuk mengulang setiap gambar dalam daftar. Untuk LMDB, perulangan juga diperlukan karena membuat objek CIFAR_Image untuk setiap gambar dan meta datanya.

Penyesuaian terkecil adalah dengan metode HDF5. File HFD5 tidak memiliki batasan ukuran file selain dari batasan eksternal atau ukuran dataset, jadi semua gambar dimasukkan ke dalam satu dataset, seperti sebelumnya.

* menyiapkan dataset

Sebelum menjalankan eksperimen lagi, pertama-tamagandakan ukuran dataset sehingga dapat menguji hingga 100.000 gambar:

```
cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
```

* eksperimen menyimpan banyak gambar

Membuat kamus yang menangani semua fungsi dengan store_many_ dan menjalankan eksperimen:

```
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```
Berikut adalah kode yang menghasilkan grafik di atas:
```
import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)
```
## Reading a single image
Pertama, pertimbangkan kasus untuk membaca satu gambar kembali ke dalam larik untuk masing-masing dari ketiga metode tersebut.

* dengan disk

Dari ketiga metode tersebut, LMDB memerlukan kerja keras ketika membaca file gambar kembali dari memori, karena adanya langkah serialisasi. 

Pertama, membaca satu gambar dan meta-nya dari file .png dan .csv:
```
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label
```

* dengan LMDB

Selanjutnya, baca gambar dan meta yang sama dari LMDB dengan membuka lingkungan dan memulai transaksi baca:

```
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label
```

Berikut adalah beberapa hal yang perlu diperhatikan mengenai cuplikan kode di atas:

- Line 13: Bendera readonly=True menetapkan bahwa tidak ada penulisan yang diizinkan pada file LMDB sampai transaksi selesai. Dalam istilah database, ini setara dengan mengambil kunci baca.
- Line 20: Untuk mengambil objek CIFAR_Image, Anda perlu membalikkan langkah yang kita ambil untuk mengambilnya ketika kita menulisnya. Di sinilah get_image() dari objek tersebut sangat membantu.

* dengan HDF5

HDF5 terlihat sangat mirip dengan proses penulisan. Berikut ini adalah kode untuk membuka dan membaca file HDF5 dan mengurai gambar dan meta yang sama:

```
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label
```

Mengakses berbagai kumpulan data di dalam file dengan mengindeks objek file menggunakan nama kumpulan data yang diawali dengan garis miring /. Seperti sebelumnya, Anda dapat membuat kamus yang berisi semua fungsi baca:

```
_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```

* eksperimen menyimpan gambar tunggal

Percobaan untuk membaca satu gambar akan memberikan hasil yang agak sepele, tetapi inilah kode percobaannya.

```
from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```
Berikut ini adalah hasil percobaan untuk membaca satu gambar:
| Method | Read Single Image + Meta|]
| ------ | ------------------------|
| Disk   | 1.61970 ms                |
| LMDB   | 4.52063 ms                |
| HDF5   | 1.98036 ms                |

Sedikit lebih cepat untuk membaca file .png dan .csv secara langsung dari disk, tetapi ketiga metode ini bekerja dengan sangat cepat. 

## Reading many images

Menyesuaikan kode untuk membaca banyak gambar sekaligus.

* penyesesuaian code untuk banyak gambar

Memperluas fungsi di atas, dapat membuat fungsi dengan read_many_, yang dapat digunakan untuk eksperimen berikutnya. Seperti sebelumnya.

```
def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))

    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels

def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object 
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels

def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")

    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")

    return images, labels

_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)
```
Dengan fungsi membaca yang tersimpan dalam kamus, seperti halnya fungsi menulis, maka sudah siap untuk bereksperimen.

* eksperimen menyimpan banyak gambar

Dapat menjalankan eksperimen untuk membaca banyak gambar:


```
from timeit import timeit

read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=1,
            globals=globals(),
        )
        read_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}")
```

Apabila menyimpan gambar sebagai file .png, ada perbedaan besar antara waktu tulis dan baca. Namun, dengan LMDB dan HDF5, perbedaannya tidak terlalu mencolok. Secara keseluruhan, meskipun waktu baca lebih penting daripada waktu tulis.

## considering disk usage
Kecepatan bukanlah satu-satunya faktor kinerja yang penting; ruang disk juga merupakan pertimbangan yang signifikan terutama saat berurusan dengan kumpulan data yang besar. 

Misalnya, jika memiliki kumpulan data gambar besar seperti 3TB, penggunaan metode penyimpanan alternatif dapat menghasilkan kinerja yang lebih baik namun memerlukan ruang disk tambahan untuk menyimpan salinan data tersebut. Sehingga, meskipun dapat meningkatkan kinerja penggunaan data gambar, perlu memastikan ketersediaan ruang disk yang memadai.